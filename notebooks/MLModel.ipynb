{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94708072-e91c-49c5-b9f4-46b13af16e45",
   "metadata": {},
   "source": [
    "# Demonstration Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12388667-427b-4a79-b07a-af89c7f7231c",
   "metadata": {},
   "source": [
    "This notebook outlines a simple machine-learning process using [Polars](https://pola.rs/) as the dataframe tool, and [scikit-learn](https://scikit-learn.org/stable/index.html) for modelling. The (fake) data records ice-cream sales versus mean daily temperatures. The model is intended to be able to predict ice-cream sales based on daily temperatures.\n",
    "\n",
    "The following tasks will be executed:\n",
    "1. Read initial data from S3\n",
    "2. Separate the data into training and tests sets\n",
    "3. Train a linear regression model, verifying that its R^{2} is adequate\n",
    "4. Test the remaining data against the predictions of the model\n",
    "5. If adequate, save the model to S3\n",
    "\n",
    "Then, we will assume the model is being used at a later date to analyse new data (which does not conform to the previous data).\n",
    "1. Load the serialised model from S3\n",
    "2. Read the new data from S3\n",
    "3. Compare it with the predictions of the loaded model and demonstrate that it is a poor fit\n",
    "4. Create new training and test data sets\n",
    "5. Retrain and test the model\n",
    "6. Save the new parameters\n",
    "\n",
    "First we install the Polars library on the instance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a87323-7c78-475d-9f39-8f21e3669879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install polars # does not need to be run as Polars is installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5722d00-0630-46a6-80b9-9e20c733b6f3",
   "metadata": {},
   "source": [
    "Then we import all the necessary dependencies. The other libraries are either part of Python or included on the instance by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02c1d39-4cd9-414c-a7f2-8eb1955e5717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import io\n",
    "import boto3\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f72909f-25c2-49e0-9b71-408479d3739b",
   "metadata": {},
   "source": [
    "Specify the bucket and the source path of the initial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e511f626-0d37-495a-b018-7184861e5aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'sfc-mt-sagemaker-demo'\n",
    "DATA1 = f's3://{BUCKET}/data1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a9514-43e4-4298-aaf1-5d252718adb5",
   "metadata": {},
   "source": [
    "(Setting up boto3 client and deleting any previous run parameters.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c08c807d-6ffd-4326-ae28-e96dbc5ca3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted params/v1/params.pkl from sfc-mt-sagemaker-demo\n",
      "Deleted params/v2/params.pkl from sfc-mt-sagemaker-demo\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "try:\n",
    "    s3.delete_object(Bucket='sfc-mt-sagemaker-demo', Key='params/v1/params.pkl')\n",
    "    print(\"Deleted params/v1/params.pkl from sfc-mt-sagemaker-demo\")\n",
    "    s3.delete_object(Bucket='sfc-mt-sagemaker-demo', Key='params/v2/params.pkl')\n",
    "    print(\"Deleted params/v2/params.pkl from sfc-mt-sagemaker-demo\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('Deletion failed, possibly no files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769c726d-6b55-4555-b2c2-63bf7dd61320",
   "metadata": {},
   "source": [
    "## Read the initial data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa135d26-a9a0-495f-9a8b-99536101f2ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (AccessDenied) when calling the GetObject operation: User: arn:aws:sts::344210435447:assumed-role/dev-sagemaker-execution-role/SageMaker is not authorized to perform: s3:GetObject on resource: \"arn:aws:s3:::sfc-mt-sagemaker-demo/data1/sales1.parquet\" because no identity-based policy allows the s3:GetObject action",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43ms3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBUCKET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata1/sales1.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:601\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    598\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/context.py:123\u001b[0m, in \u001b[0;36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[1;32m    122\u001b[0m     hook()\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:1074\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m request_context\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1071\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_code_override\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1072\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1073\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1074\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (AccessDenied) when calling the GetObject operation: User: arn:aws:sts::344210435447:assumed-role/dev-sagemaker-execution-role/SageMaker is not authorized to perform: s3:GetObject on resource: \"arn:aws:s3:::sfc-mt-sagemaker-demo/data1/sales1.parquet\" because no identity-based policy allows the s3:GetObject action"
     ]
    }
   ],
   "source": [
    "response = s3.get_object(Bucket=BUCKET, Key='data1/sales1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98817fbe-af32-4a7c-ab2d-f5dc8066b367",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "object-store error: The operation lacked the necessary privileges to complete for path data1/sales1.parquet: Error performing HEAD https://s3.eu-west-2.amazonaws.com/sfc-mt-sagemaker-demo/data1/sales1.parquet in 45.824217ms - Server returned non-2xx status code: 403 Forbidden: \n\nThis error occurred with the following context stack:\n\t[1] 'parquet scan'\n\t[2] 'sink'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df1\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/polars/_utils/deprecation.py:128\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    125\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m    126\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[1;32m    127\u001b[0m     )\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/polars/_utils/deprecation.py:128\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    125\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m    126\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[1;32m    127\u001b[0m     )\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/polars/io/parquet/functions.py:289\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(source, columns, n_rows, row_index_name, row_index_offset, parallel, use_statistics, hive_partitioning, glob, schema, hive_schema, try_parse_hive_dates, rechunk, low_memory, storage_options, credential_provider, retries, use_pyarrow, pyarrow_options, memory_map, include_file_paths, missing_columns, allow_missing_columns)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m         lf \u001b[38;5;241m=\u001b[39m lf\u001b[38;5;241m.\u001b[39mselect(columns)\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/polars/_utils/deprecation.py:97\u001b[0m, in \u001b[0;36mdeprecate_streaming_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min-memory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstreaming\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/polars/lazyframe/opt_flags.py:330\u001b[0m, in \u001b[0;36mforward_old_opt_flags.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m         optflags \u001b[38;5;241m=\u001b[39m cb(optflags, kwargs\u001b[38;5;241m.\u001b[39mpop(key))  \u001b[38;5;66;03m# type: ignore[no-untyped-call,unused-ignore]\u001b[39;00m\n\u001b[1;32m    329\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizations\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m optflags\n\u001b[0;32m--> 330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/polars/lazyframe/frame.py:2335\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, engine, background, optimizations, **_kwargs)\u001b[0m\n\u001b[1;32m   2333\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2334\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mOSError\u001b[0m: object-store error: The operation lacked the necessary privileges to complete for path data1/sales1.parquet: Error performing HEAD https://s3.eu-west-2.amazonaws.com/sfc-mt-sagemaker-demo/data1/sales1.parquet in 45.824217ms - Server returned non-2xx status code: 403 Forbidden: \n\nThis error occurred with the following context stack:\n\t[1] 'parquet scan'\n\t[2] 'sink'\n"
     ]
    }
   ],
   "source": [
    "df1 = pl.read_parquet(DATA1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088cc31f-0bea-4361-947a-d8e6da06bd7d",
   "metadata": {},
   "source": [
    "## Separate into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b547c3-cf9a-45cb-9a35-1c9b506d1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FRAC = 0.7\n",
    "df_train1 = df1.sample(fraction=TRAIN_FRAC, with_replacement=False, shuffle=True, seed=55)\n",
    "df_test1 = df1.join(df_train1, on=df1.columns, how='anti')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3de43f-2c43-420a-88e0-5e4a8c8f8ff0",
   "metadata": {},
   "source": [
    "## Training\n",
    "1. Put the data into numpy arrays for use by scikit-learn\n",
    "2. Create and fit the model\n",
    "3. Get the predicted values from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737ab36-5199-49e8-8204-4003a71a0b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df_train1['MeanDailyTemperature'].to_numpy().reshape(-1,1)\n",
    "y1 = df_train1['IceCreamSales'].to_numpy()\n",
    "model1 = LinearRegression()\n",
    "model1.fit(x1, y1)\n",
    "y_pred1 = model1.predict(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612eaa28-c44b-4038-89be-5c6701bc156f",
   "metadata": {},
   "source": [
    "### Plot the training set and regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f201a262-60d0-434a-963f-b02b1d81bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.scatter(x1, y1, alpha=0.5, s=10, label='Ice Cream Data')\n",
    "ax.plot(x1, y_pred1, color='red', linewidth=2, label='Regression Line')\n",
    "ax.set_title('Ice Cream Sales Vs Mean Daily Temperature, with Regression')\n",
    "ax.set_xlabel('Mean Daily Temperature (°C)')\n",
    "ax.set_ylabel('Ice Cream Sales (£)')\n",
    "ax.ticklabel_format(style='plain', axis='y')\n",
    "ax.grid(True, linestyle=':', alpha=0.7)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2476235-d038-4109-bd2f-0ad946e5461f",
   "metadata": {},
   "source": [
    "Visually, this looks like a very good fit, but we should measure the fit numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c13d1c0-1127-4d52-99e9-ad08a22595ad",
   "metadata": {},
   "source": [
    "### Verify that the R^{2} is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe36a363-0c16-41df-ae3b-7d0bb3db5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_1 = r2_score(y1, y_pred1)\n",
    "\n",
    "print(f'The model has an R2 score {r2_1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a036ac95-0fc2-4179-b81a-f6dc2901d442",
   "metadata": {},
   "source": [
    "This is a high value so we are happy that the fit is good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b57b3b-bb1a-46e6-9a3c-36c976fc2704",
   "metadata": {},
   "source": [
    "## Check model against test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70c95a-8d8a-4ef5-9fba-3bb96f270c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1 = df_test1['MeanDailyTemperature'].to_numpy().reshape(-1,1)\n",
    "y_test1 = df_test1['IceCreamSales'].to_numpy()\n",
    "y_test_pred1 = model1.predict(x_test1)\n",
    "r2_test1 = r2_score(y_test1, y_test_pred1)\n",
    "print(f'The model scores {r2_test1} on test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de0184f-228f-4cf9-b47e-c2d1ccfabc69",
   "metadata": {},
   "source": [
    "Again, this is a high value, so we are happy that the model is robust.\n",
    "\n",
    "Now we can extract the model parameters if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971f5b8-313f-49f0-83b7-f086fb8a7592",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = model1.coef_[0]\n",
    "intercept = model1.intercept_\n",
    "print(f'The model slope is {slope}, and the intercept is {intercept}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea5306-b837-48a1-8d17-94e2c01051de",
   "metadata": {},
   "source": [
    "## Save the model to S3\n",
    "\n",
    "We will serialise the model using the built-in [pickle](https://docs.python.org/3/library/pickle.html) module. For a simple linear model, it is possible just to save the model parameters in plain text, but it is better practice to save the full model instance for re-use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c46177-afd6-4047-b7c8-cdf47e071432",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = io.BytesIO()\n",
    "pickle.dump(model1, buffer)\n",
    "buffer.seek(0)\n",
    "\n",
    "s3.upload_fileobj(buffer, BUCKET, 'params/v1/params.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553d5fa7-33b1-47a3-8b96-74f96fb1b033",
   "metadata": {},
   "source": [
    "## New data\n",
    "\n",
    "Now we imagine that some time has passed and new data is available. First the analyst reads in the model that has been saved to S3. Then s/he reads in the new data and compares it to the model predictions. If these turn out to be a poor fit, the training/testing/serialisation cycle is restarted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52188b9d-dc3d-4c64-86c0-a0fa18b44871",
   "metadata": {},
   "source": [
    "## Retrieve the serialised model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae3d4f-845f-4869-9ec9-f0ae61c6991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "download = io.BytesIO()\n",
    "s3.download_fileobj(BUCKET, 'params/v1/params.pkl', download)\n",
    "download.seek(0)\n",
    "loaded_model = pickle.load(download)\n",
    "loaded_model.coef_[0], loaded_model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6c295d-c6e6-457f-86ec-07f00b8fd27d",
   "metadata": {},
   "source": [
    "## Retrieve the latest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2cecaa-ea7c-444a-9b1c-ee7b3db0d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA2 = f's3://{BUCKET}/data2/'\n",
    "df2 = pl.read_parquet(DATA2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de19c962-325b-45f0-909c-d3d8d477ff7d",
   "metadata": {},
   "source": [
    "## Compare the model predictions to the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42439a89-bedb-4458-b0b0-c6af49aeb40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = df2['MeanDailyTemperature'].to_numpy().reshape(-1,1)\n",
    "y2 = df2['IceCreamSales'].to_numpy()\n",
    "y_pred2 = loaded_model.predict(x2)\n",
    "r2_loaded = r2_score(y2, y_pred2)\n",
    "print(f'The R2 of the new data is {r2_loaded}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4110d226-ab2a-45ea-b598-ce20a3c6a9d7",
   "metadata": {},
   "source": [
    "This is a much lower score, indication that the model is not doing as good a job as it was previously. We can see this if we plot the data and regression line..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2fcb0b-ecba-4702-9c86-ce579edc36f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "ax2.scatter(x2, y2, alpha=0.5, s=10, label='Ice Cream Data')\n",
    "ax2.plot(x2, y_pred2, color='red', linewidth=2, label='Regression Line')\n",
    "ax2.set_title('Ice Cream Sales Vs Mean Daily Temperature, with Regression')\n",
    "ax2.set_xlabel('Mean Daily Temperature (°C)')\n",
    "ax2.set_ylabel('Ice Cream Sales (£)')\n",
    "ax2.ticklabel_format(style='plain', axis='y')\n",
    "ax2.grid(True, linestyle=':', alpha=0.7)\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485bbae2-ec79-45c7-b27a-40f544bb0a0d",
   "metadata": {},
   "source": [
    "## Repeat Training, Testing and Serialisation\n",
    "\n",
    "### Separate the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c4465-892b-46be-b6e2-05e7cbeeb743",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2 = df2.sample(fraction=TRAIN_FRAC, with_replacement=False, shuffle=True, seed=55)\n",
    "df_test2 = df2.join(df_train2, on=df2.columns, how='anti')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb99cd3-0bd6-408b-9cec-558094024854",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "In this case, we will simply train the model on the new data set. Alternatively, we could train it n the new data and previous data combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482d7fe3-6ef1-409d-a953-1610278f0354",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = df_train2['MeanDailyTemperature'].to_numpy().reshape(-1,1)\n",
    "y2 = df_train2['IceCreamSales'].to_numpy()\n",
    "model2 = LinearRegression()\n",
    "model2.fit(x2, y2)\n",
    "y_pred2 = model2.predict(x2)\n",
    "r2_2 = r2_score(y2, y_pred2)\n",
    "\n",
    "print(f'The new model has an R2 score {r2_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dfe78b-2955-4446-8ae4-1a17d76bea9d",
   "metadata": {},
   "source": [
    "This is much better and we can see the effect using another plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020fd3d-d4bf-433a-b5f7-4c6d3e56be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "ax2.scatter(x2, y2, alpha=0.5, s=10, label='Ice Cream Data')\n",
    "ax2.plot(x2, y_pred2, color='red', linewidth=2, label='Regression Line')\n",
    "ax2.set_title('Ice Cream Sales Vs Mean Daily Temperature, with Regression')\n",
    "ax2.set_xlabel('Mean Daily Temperature (°C)')\n",
    "ax2.set_ylabel('Ice Cream Sales (£)')\n",
    "ax2.ticklabel_format(style='plain', axis='y')\n",
    "ax2.grid(True, linestyle=':', alpha=0.7)\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc20bd8-207e-46f4-b8dd-2ee4b59419dc",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2951d0b6-5543-4ba0-b0bb-0eab2ddfcff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test2 = df_test2['MeanDailyTemperature'].to_numpy().reshape(-1,1)\n",
    "y_test2 = df_test2['IceCreamSales'].to_numpy()\n",
    "y_test_pred2 = model2.predict(x_test2)\n",
    "r2_test2 = r2_score(y_test2, y_test_pred2)\n",
    "print(f'The new model scores {r2_test2} on test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2507b09d-7da6-44b5-bf83-125b579779ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = model2.coef_[0]\n",
    "intercept = model2.intercept_\n",
    "print(f'The new model slope is {slope}, and the intercept is {intercept}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a6b3b3-d467-4806-b251-91088df1a82b",
   "metadata": {},
   "source": [
    "### Serialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca5abed-c24a-407d-97da-c04635204e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = io.BytesIO()\n",
    "pickle.dump(model2, buffer)\n",
    "buffer.seek(0)\n",
    "\n",
    "s3.upload_fileobj(buffer, BUCKET, 'params/v2/params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8474951d-3fad-4e6d-ba56-636dbd1bc745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
