{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94708072-e91c-49c5-b9f4-46b13af16e45",
   "metadata": {},
   "source": [
    "# Demonstration Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12388667-427b-4a79-b07a-af89c7f7231c",
   "metadata": {},
   "source": [
    "This notebook outlines a simple machine-learning process using [Polars](https://pola.rs/) as the dataframe tool, and [scikit-learn](https://scikit-learn.org/stable/index.html) for modelling. The (fake) data records ice-cream sales versus mean daily temperatures. The model is intended to be able to predict ice-cream sales based on daily temperatures.\n",
    "\n",
    "The following tasks will be executed:\n",
    "1. Read initial data from S3\n",
    "2. Separate the data into training and tests sets\n",
    "3. Train a linear regression model, verifying that its R^{2} is adequate\n",
    "4. Test the remaining data against the predictions of the model\n",
    "5. If adequate, save the model to S3\n",
    "\n",
    "Then, we will assume the model is being used at a later date to analyse new data (which does not conform to the previous data).\n",
    "1. Load the serialised model from S3\n",
    "2. Read the new data from S3\n",
    "3. Compare it with the predictions of the loaded model and demonstrate that it is a poor fit\n",
    "4. Create new training and test data sets\n",
    "5. Retrain and test the model\n",
    "6. Save the new parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5722d00-0630-46a6-80b9-9e20c733b6f3",
   "metadata": {},
   "source": [
    "First, we import all the necessary dependencies. The other libraries are either part of Python or included on the instance by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c1d39-4cd9-414c-a7f2-8eb1955e5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import io\n",
    "import boto3\n",
    "import re\n",
    "import os\n",
    "from enum import Enum\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924d04a-3b23-40a1-9360-125f4ae022f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The deployment environment for this notebook is {os.environ[\"ENV\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c5014-f04b-4edc-b8ff-ec080fa71219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.version import ModelVersionManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f72909f-25c2-49e0-9b71-408479d3739b",
   "metadata": {},
   "source": [
    "Specify the bucket and the source path of the initial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511f626-0d37-495a-b018-7184861e5aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'sfc-mt-sagemaker-demo'\n",
    "DATA1 = f's3://{BUCKET}/data1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a9514-43e4-4298-aaf1-5d252718adb5",
   "metadata": {},
   "source": [
    "(Setting up boto3 client and deleting any previous run parameters.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c807d-6ffd-4326-ae28-e96dbc5ca3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "try:\n",
    "    s3.delete_object(Bucket='sfc-mt-sagemaker-demo', Key='params/v1/params.pkl')\n",
    "    print(\"Deleted params/v1/params.pkl from sfc-mt-sagemaker-demo\")\n",
    "    s3.delete_object(Bucket='sfc-mt-sagemaker-demo', Key='params/v2/params.pkl')\n",
    "    print(\"Deleted params/v2/params.pkl from sfc-mt-sagemaker-demo\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('Deletion failed, possibly no files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769c726d-6b55-4555-b2c2-63bf7dd61320",
   "metadata": {},
   "source": [
    "## Read the initial data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98817fbe-af32-4a7c-ab2d-f5dc8066b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pl.read_parquet(DATA1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051bf60f-7017-4a98-8cf3-c7519c87ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1fa05c-8d61-42fe-9a1d-4887bc57fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.schema_reader import GlueSchemaReader\n",
    "gsr = GlueSchemaReader(\"main-data-engineering-database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf4ab9b-3aa9-459c-a87d-248c745ba3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plschema = gsr.get_polars_schema(\"dataset_ind_cqc_estimated_missing_ascwds_filled_posts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088cc31f-0bea-4361-947a-d8e6da06bd7d",
   "metadata": {},
   "source": [
    "## Separate into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b547c3-cf9a-45cb-9a35-1c9b506d1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FRAC = 0.7\n",
    "df_train1 = df1.sample(fraction=TRAIN_FRAC, with_replacement=False, shuffle=True, seed=55)\n",
    "df_test1 = df1.join(df_train1, on=df1.columns, how='anti')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3de43f-2c43-420a-88e0-5e4a8c8f8ff0",
   "metadata": {},
   "source": [
    "## Training\n",
    "1. Put the data into numpy arrays for use by scikit-learn\n",
    "2. Create and fit the model\n",
    "3. Get the predicted values from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737ab36-5199-49e8-8204-4003a71a0b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df_train1['MeanDailyTemperature'].to_numpy().reshape(-1,1)\n",
    "y1 = df_train1['IceCreamSales'].to_numpy()\n",
    "model1 = LinearRegression()\n",
    "model1.fit(x1, y1)\n",
    "y_pred1 = model1.predict(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612eaa28-c44b-4038-89be-5c6701bc156f",
   "metadata": {},
   "source": [
    "### Plot the training set and regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f201a262-60d0-434a-963f-b02b1d81bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.scatter(x1, y1, alpha=0.5, s=10, label='Ice Cream Data')\n",
    "ax.plot(x1, y_pred1, color='red', linewidth=2, label='Regression Line')\n",
    "ax.set_title('Ice Cream Sales Vs Mean Daily Temperature, with Regression')\n",
    "ax.set_xlabel('Mean Daily Temperature (°C)')\n",
    "ax.set_ylabel('Ice Cream Sales (£)')\n",
    "ax.ticklabel_format(style='plain', axis='y')\n",
    "ax.grid(True, linestyle=':', alpha=0.7)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2476235-d038-4109-bd2f-0ad946e5461f",
   "metadata": {},
   "source": [
    "Visually, this looks like a very good fit, but we should measure the fit numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c13d1c0-1127-4d52-99e9-ad08a22595ad",
   "metadata": {},
   "source": [
    "### Verify that the R^{2} is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe36a363-0c16-41df-ae3b-7d0bb3db5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_1 = r2_score(y1, y_pred1)\n",
    "\n",
    "print(f'The model has an R2 score {r2_1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a036ac95-0fc2-4179-b81a-f6dc2901d442",
   "metadata": {},
   "source": [
    "This is a high value so we are happy that the fit is good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b57b3b-bb1a-46e6-9a3c-36c976fc2704",
   "metadata": {},
   "source": [
    "## Check model against test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70c95a-8d8a-4ef5-9fba-3bb96f270c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1 = df_test1['MeanDailyTemperature'].to_numpy().reshape(-1,1)\n",
    "y_test1 = df_test1['IceCreamSales'].to_numpy()\n",
    "y_test_pred1 = model1.predict(x_test1)\n",
    "r2_test1 = r2_score(y_test1, y_test_pred1)\n",
    "print(f'The model scores {r2_test1} on test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de0184f-228f-4cf9-b47e-c2d1ccfabc69",
   "metadata": {},
   "source": [
    "Again, this is a high value, so we are happy that the model is robust.\n",
    "\n",
    "Now we can extract the model parameters if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971f5b8-313f-49f0-83b7-f086fb8a7592",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = model1.coef_[0]\n",
    "intercept = model1.intercept_\n",
    "print(f'The model slope is {slope}, and the intercept is {intercept}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea5306-b837-48a1-8d17-94e2c01051de",
   "metadata": {},
   "source": [
    "## Save the model to S3\n",
    "\n",
    "We will serialise the model using the built-in [pickle](https://docs.python.org/3/library/pickle.html) module. For a simple linear model, it is possible just to save the model parameters in plain text, but it is better practice to save the full model instance for re-use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a10f3a-ad48-4a11-a9e2-d6f41d98a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_store_name = 'models/test/v2/ice_cream'\n",
    "vm = ModelVersionManager(BUCKET, 'params/v2', param_store_name)\n",
    "vm.prompt_and_save(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c46177-afd6-4047-b7c8-cdf47e071432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buffer = io.BytesIO()\n",
    "# pickle.dump(model1, buffer)\n",
    "# buffer.seek(0)\n",
    "\n",
    "# s3.upload_fileobj(buffer, BUCKET, 'params/v1/params.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553d5fa7-33b1-47a3-8b96-74f96fb1b033",
   "metadata": {},
   "source": [
    "## New data\n",
    "\n",
    "Now we imagine that some time has passed and new data is available. First the analyst reads in the model that has been saved to S3. Then s/he reads in the new data and compares it to the model predictions. If these turn out to be a poor fit, the training/testing/serialisation cycle is restarted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52188b9d-dc3d-4c64-86c0-a0fa18b44871",
   "metadata": {},
   "source": [
    "## Retrieve the serialised model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae3d4f-845f-4869-9ec9-f0ae61c6991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "download = io.BytesIO()\n",
    "s3.download_fileobj(BUCKET, 'params/v1/params.pkl', download)\n",
    "download.seek(0)\n",
    "loaded_model = pickle.load(download)\n",
    "loaded_model.coef_[0], loaded_model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6c295d-c6e6-457f-86ec-07f00b8fd27d",
   "metadata": {},
   "source": [
    "## Retrieve the latest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2cecaa-ea7c-444a-9b1c-ee7b3db0d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA2 = f's3://{BUCKET}/data2/'\n",
    "df2 = pl.read_parquet(DATA2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de19c962-325b-45f0-909c-d3d8d477ff7d",
   "metadata": {},
   "source": [
    "## Compare the model predictions to the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42439a89-bedb-4458-b0b0-c6af49aeb40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = df2['MeanDailyTemperature'].to_numpy().reshape(-1,1)\n",
    "y2 = df2['IceCreamSales'].to_numpy()\n",
    "y_pred2 = loaded_model.predict(x2)\n",
    "r2_loaded = r2_score(y2, y_pred2)\n",
    "print(f'The R2 of the new data is {r2_loaded}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4110d226-ab2a-45ea-b598-ce20a3c6a9d7",
   "metadata": {},
   "source": [
    "This is a much lower score, indication that the model is not doing as good a job as it was previously. We can see this if we plot the data and regression line..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2fcb0b-ecba-4702-9c86-ce579edc36f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "ax2.scatter(x2, y2, alpha=0.5, s=10, label='Ice Cream Data')\n",
    "ax2.plot(x2, y_pred2, color='red', linewidth=2, label='Regression Line')\n",
    "ax2.set_title('Ice Cream Sales Vs Mean Daily Temperature, with Regression')\n",
    "ax2.set_xlabel('Mean Daily Temperature (°C)')\n",
    "ax2.set_ylabel('Ice Cream Sales (£)')\n",
    "ax2.ticklabel_format(style='plain', axis='y')\n",
    "ax2.grid(True, linestyle=':', alpha=0.7)\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485bbae2-ec79-45c7-b27a-40f544bb0a0d",
   "metadata": {},
   "source": [
    "## Repeat Training, Testing and Serialisation\n",
    "\n",
    "### Separate the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c4465-892b-46be-b6e2-05e7cbeeb743",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2 = df2.sample(fraction=TRAIN_FRAC, with_replacement=False, shuffle=True, seed=55)\n",
    "df_test2 = df2.join(df_train2, on=df2.columns, how='anti')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb99cd3-0bd6-408b-9cec-558094024854",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "In this case, we will simply train the model on the new data set. Alternatively, we could train it n the new data and previous data combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482d7fe3-6ef1-409d-a953-1610278f0354",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = df_train2['MeanDailyTemperature'].to_numpy().reshape(-1,1)\n",
    "y2 = df_train2['IceCreamSales'].to_numpy()\n",
    "model2 = LinearRegression()\n",
    "model2.fit(x2, y2)\n",
    "y_pred2 = model2.predict(x2)\n",
    "r2_2 = r2_score(y2, y_pred2)\n",
    "\n",
    "print(f'The new model has an R2 score {r2_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dfe78b-2955-4446-8ae4-1a17d76bea9d",
   "metadata": {},
   "source": [
    "This is much better and we can see the effect using another plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020fd3d-d4bf-433a-b5f7-4c6d3e56be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "ax2.scatter(x2, y2, alpha=0.5, s=10, label='Ice Cream Data')\n",
    "ax2.plot(x2, y_pred2, color='red', linewidth=2, label='Regression Line')\n",
    "ax2.set_title('Ice Cream Sales Vs Mean Daily Temperature, with Regression')\n",
    "ax2.set_xlabel('Mean Daily Temperature (°C)')\n",
    "ax2.set_ylabel('Ice Cream Sales (£)')\n",
    "ax2.ticklabel_format(style='plain', axis='y')\n",
    "ax2.grid(True, linestyle=':', alpha=0.7)\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc20bd8-207e-46f4-b8dd-2ee4b59419dc",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2951d0b6-5543-4ba0-b0bb-0eab2ddfcff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test2 = df_test2['MeanDailyTemperature'].to_numpy().reshape(-1,1)\n",
    "y_test2 = df_test2['IceCreamSales'].to_numpy()\n",
    "y_test_pred2 = model2.predict(x_test2)\n",
    "r2_test2 = r2_score(y_test2, y_test_pred2)\n",
    "print(f'The new model scores {r2_test2} on test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2507b09d-7da6-44b5-bf83-125b579779ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = model2.coef_[0]\n",
    "intercept = model2.intercept_\n",
    "print(f'The new model slope is {slope}, and the intercept is {intercept}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a6b3b3-d467-4806-b251-91088df1a82b",
   "metadata": {},
   "source": [
    "### Serialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca5abed-c24a-407d-97da-c04635204e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = io.BytesIO()\n",
    "pickle.dump(model2, buffer)\n",
    "buffer.seek(0)\n",
    "\n",
    "s3.upload_fileobj(buffer, BUCKET, 'params/v2/params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8474951d-3fad-4e6d-ba56-636dbd1bc745",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChangeType(Enum):\n",
    "    MAJOR = 1\n",
    "    MINOR = 2\n",
    "    PATCH = 3\n",
    "\n",
    "class ModelVersionManager:\n",
    "    \"\"\"\n",
    "    Manages semantic versioning for machine learning models using AWS Systems Manager\n",
    "    Parameter Store.\n",
    "\n",
    "    Attributes:\n",
    "        param_store_name (str): The name of the parameter in Parameter Store.\n",
    "        s3_bucket (str): The S3 bucket where models are stored.\n",
    "        s3_prefix (str): The base prefix for model files in S3.\n",
    "        ssm_client: The Boto3 client for Systems Manager.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, param_store_name, s3_bucket, s3_prefix):\n",
    "        \"\"\"\n",
    "        Initializes the ModelVersionManager.\n",
    "\n",
    "        Args:\n",
    "            param_store_name (str): The name of the parameter in Parameter Store.\n",
    "            s3_bucket (str): The S3 bucket where models are stored.\n",
    "            s3_prefix (str): The base prefix for model files in S3.\n",
    "        \"\"\"\n",
    "        self.param_store_name = param_store_name\n",
    "        self.s3_bucket = s3_bucket\n",
    "        self.s3_prefix = s3_prefix\n",
    "        self.ssm_client = boto3.client('ssm')\n",
    "        self.s3_client = boto3.client('s3')\n",
    "\n",
    "    def _get_current_version(self):\n",
    "        \"\"\"\n",
    "        Retrieves the current model version from Parameter Store.\n",
    "\n",
    "        Returns:\n",
    "            str: The current version string (e.g., \"1.2.3\").\n",
    "\n",
    "        Raises:\n",
    "            ClientError: If there is an error while connecting to the AWS API\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.ssm_client.get_parameter(Name=self.param_store_name, WithDecryption=False)\n",
    "            return response['Parameter']['Value']\n",
    "        except self.ssm_client.exceptions.ParameterNotFound:\n",
    "            print(f\"Parameter '{self.param_store_name}' not found. Initializing to 0.1.0.\")\n",
    "            return \"0.1.0\"\n",
    "        except ClientError as e:\n",
    "            print(f\"Boto3 Error while retrieving parameter: {e}\")\n",
    "            raise e\n",
    "\n",
    "\n",
    "    def _update_parameter_store(self, new_version: str) -> None:\n",
    "        \"\"\"\n",
    "        Updates the version number in Parameter Store.\n",
    "\n",
    "        Args:\n",
    "            new_version (str): The new version string.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.ssm_client.put_parameter(\n",
    "                Name=self.param_store_name,\n",
    "                Value=new_version,\n",
    "                Type='String',\n",
    "                Overwrite=True\n",
    "            )\n",
    "            print(f\"Successfully updated Parameter Store with new version: {new_version}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating Parameter Store: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def _increment_version(self, current_version: str, change_type: ChangeType) -> str:\n",
    "        \"\"\"\n",
    "        Increments the version number based on the change type.\n",
    "\n",
    "        Args:\n",
    "            current_version (str): The current version string.\n",
    "            change_type (str): 'major', 'minor', or 'patch'.\n",
    "\n",
    "        Returns:\n",
    "            str: The new version string.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the change type is invalid.\n",
    "        \"\"\"\n",
    "        parts = [int(p) for p in current_version.split('.')]\n",
    "        if change_type == '1':\n",
    "            parts[0] += 1\n",
    "            parts[1] = 0\n",
    "            parts[2] = 0\n",
    "        elif change_type == '2':\n",
    "            parts[1] += 1\n",
    "            parts[2] = 0\n",
    "        elif change_type == '3':\n",
    "            parts[2] += 1\n",
    "        else:\n",
    "            raise ValueError(\"Invalid change type. Must be  '1'(major), 'minor', or 'patch'.\")\n",
    "\n",
    "        return \".\".join(map(str, parts))\n",
    "\n",
    "    def get_new_version(self, change_type: ChangeType) -> str:\n",
    "        \"\"\"\n",
    "        Calculates and returns the new version number.\n",
    "\n",
    "        Args:\n",
    "            change_type (ChangeType): 'MAJOR', 'MINOR', or 'PATCH'.\n",
    "\n",
    "        Returns:\n",
    "            str: The new version string.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            current_version = self._get_current_version()\n",
    "            new_version = self._increment_version(current_version, change_type)\n",
    "            return new_version\n",
    "        except ValueError as e:\n",
    "            print(f\"Error getting new version: {e}\")\n",
    "\n",
    "\n",
    "    def save_model(self, model: BaseEstimator, new_version: str):\n",
    "        \"\"\"\n",
    "        Saves the trained model to S3 with the version number in the path.\n",
    "\n",
    "        Args:\n",
    "            model(BaseEstimator): The trained model object to be saved.\n",
    "            new_version (str): The new version string.\n",
    "        \"\"\"\n",
    "        prefix = f\"{self.s3_prefix}/{new_version}/model.pkl\"\n",
    "        buffer = io.BytesIO()\n",
    "        pickle.dump(model, buffer)\n",
    "        buffer.seek(0)\n",
    "\n",
    "        self.s3_client.upload_fileobj(buffer, self.s3_bucket, prefix)\n",
    "\n",
    "        print(f\"Saving model to s3://{self.s3_bucket}/{prefix}\")\n",
    "\n",
    "    def _prompt_change(self) -> ChangeType | None:\n",
    "        selection = input(\"Is this a \\n1. Major?\\n2. Minor?\\n3. Patch change?\\n(1/2/3): \").lower()\n",
    "        if selection not in ['1', '2', '3']:\n",
    "            print(\"Invalid change type. Model not saved.\")\n",
    "            return None\n",
    "        match selection:\n",
    "            case '1':\n",
    "                return ChangeType.MAJOR\n",
    "            case '2':\n",
    "                return ChangeType.MINOR\n",
    "            case '3':\n",
    "                return ChangeType.PATCH\n",
    "            case _:\n",
    "                return None\n",
    "\n",
    "    def prompt_and_save(self, model):\n",
    "        \"\"\"\n",
    "        Prompts the user for a change type and handles the versioning and saving process.\n",
    "\n",
    "        Args:\n",
    "            model: The trained model object.\n",
    "        \"\"\"\n",
    "        should_save = input(\"Do you want to save this new model version? (only yes to save): \").lower()\n",
    "        if should_save != 'yes':\n",
    "            print(\"Model not saved. Exiting.\")\n",
    "            return\n",
    "\n",
    "        change_type = self._prompt_change()\n",
    "\n",
    "        new_version = self.get_new_version(change_type)\n",
    "        self.save_model(model, new_version)\n",
    "        self._update_parameter_store(new_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53eb15e-8153-44d0-9cd7-2a249484bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_BUCKET = 'spike-polars-data'\n",
    "PREFIX = 'testing/123'\n",
    "\n",
    "mvm = ModelVersionManager("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730b1f2a-c608-4470-8cb5-92a107a52bc9",
   "metadata": {},
   "source": [
    "Yup, another change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a8440-843e-48fd-b9ac-8afa5d3daf78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
